{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configurations\n",
    "\n",
    "path = 'dataset/'\n",
    "products = 'products-data*.tsv'\n",
    "reviews = 'reviews-*.tsv'\n",
    "products_column_names = ['id', 'category', 'product title']\n",
    "review_column_names =['id', 'rating', 'review_text']\n",
    "intersection_column = 'id'\n",
    "test_size_ratio = 0.2\n",
    "random_state_number = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function loads the data given 'path','name_of_file' and 'column_names'\n",
    "def data_loader(path, name_of_file , column_names):\n",
    "    current_items_list = []\n",
    "    data_files = Path(path).glob(name_of_file)\n",
    "    for file in data_files:\n",
    "        current_items_list.append(pd.read_csv(file, sep = '\\t', header = None, names = column_names))\n",
    "    return pd.concat(current_items_list)\n",
    "\n",
    "\n",
    "# This function merges the two data frames based on a common column\n",
    "def data_merger(left_data, right_data, intersection_column):\n",
    "    return pd.merge(left=left_data, right=right_data, on = intersection_column)\n",
    "\n",
    "\n",
    "# This function replaces the value of the 'column' in the 'data_frame'\n",
    "def replacer(column, replace_from, replace_to, data_frame):\n",
    "    return data_frame[column].replace(replace_from, replace_to, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'category', 'product title', 'rating', 'review_text'], dtype='object')\n",
      "Check the \"category\" column for any missing or invalid values that need to be cleaned.\n",
      "Jewelry    607\n",
      "Kitchen    513\n",
      "Ktchen     134\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Verify values in the \"class\" column after cleaning the data.\n",
      "Kitchen    647\n",
      "Jewelry    607\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Train Accuracy: 0.9990029910269193\n",
      "Test Accuracy: 0.9800796812749004\n",
      "\n",
      "Tovolo Groovy Ice Pop Molds, Spring Green set of 6, 2-pack\n",
      "\n",
      "\"golden\" and \"steel\" in \"product_title\" have caused a model error and predict that as kitchen value\n"
     ]
    }
   ],
   "source": [
    "# Read in the product-data*.tsv data files.\n",
    "df_product = data_loader(path,products,products_column_names)\n",
    "\n",
    "# Read in the reviews*.tsv data files.\n",
    "df_review = data_loader(path,reviews,review_column_names)\n",
    "\n",
    "# Merge df_product and df_review into a new DataFrame on the 'id' column. \n",
    "# The 'full_dataset' DataFrame will contain all the data.\n",
    "full_dataset = pd.merge(df_product, df_review, on='id')\n",
    "\n",
    "print(full_dataset.columns)\n",
    "full_dataset.head(3)\n",
    "\n",
    "\n",
    "print('Check the \"category\" column for any missing or invalid values that need to be cleaned.')\n",
    "print(full_dataset['category'].value_counts())\n",
    "\n",
    "# full_dataset = replacer('category','Ktchen','Kitchen',full_dataset)\n",
    "#Replace 'Ktchen' with 'Kitchen'\n",
    "full_dataset['category'].replace('Ktchen', 'Kitchen', inplace=True)\n",
    "print( )\n",
    "print('Verify values in the \"class\" column after cleaning the data.')\n",
    "print(full_dataset['category'].value_counts())\n",
    "\n",
    "# Select 'product title', 'review_text' and 'rating' as input features.\n",
    "# Select 'category' as output feature.\n",
    "input_features = full_dataset[['product title', 'review_text', 'rating']]\n",
    "output_features = full_dataset['category']\n",
    "\n",
    "\n",
    "# Split the data into training and test datasets.\n",
    "# Take a random 80/20 train/test split of the data by selecting 80% of rows for training and 20% for model testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_features, output_features, test_size=test_size_ratio, random_state=random_state_number)\n",
    "\n",
    "\n",
    "\n",
    "# Create a ColumnTransformer with three transformations:\n",
    "# TfidfVectorizer for the \"product title\" column,\n",
    "# TfidfVectorizer for the \"review_text\" column and \n",
    "# MinMaxScaler() for numerical feature, \"rating\".\n",
    "column_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('tilte_vectorizer', TfidfVectorizer(ngram_range=(1,3)), 'product title'),\n",
    "        ('review_vectorizer', TfidfVectorizer(ngram_range=(1,3)), 'review_text'),\n",
    "        (\"num_preprocess\", MinMaxScaler(), ['rating'])\n",
    "    ]\n",
    "    )\n",
    "\n",
    "# Construct a Pipeline with the ColumnTransformer and a LogisticRegression estimator.\n",
    "pipeline_transformer_lr = Pipeline([\n",
    "    ('featurizer', column_transformer),\n",
    "    # ('feature_selection', SequentialFeatureSelector(estimator=MultinomialNB(), direction='backward', cv=2, n_jobs=-1)),\n",
    "    ('lg', LogisticRegression())\n",
    "    ]\n",
    "    )\n",
    "\n",
    "# Fit the pipeline on the training data.\n",
    "pipeline_transformer_lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the pipeline by scoring accuracy on the train and test sets.\n",
    "print()\n",
    "print('Train Accuracy:', pipeline_transformer_lr.score(X_train, y_train))\n",
    "print('Test Accuracy:', pipeline_transformer_lr.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Identify incorrect predictions made by the model.\n",
    "incorrect_dataframe = full_dataset[pipeline_transformer_lr.predict(full_dataset) != full_dataset['category']]\n",
    "incorrect_dataframe\n",
    "\n",
    "# Check the incorrectly predicted sample.\n",
    "print(full_dataset.loc[254, 'product title'])\n",
    "print()\n",
    "print('\"golden\" and \"steel\" in \"product_title\" have caused a model error and predict that as kitchen value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
